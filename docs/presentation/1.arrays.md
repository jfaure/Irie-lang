# Systems-level Dependently-typed Array programming language
_All exercises up to this point were pale imitations of the abyss that now lies ahead_
## Core Goals
* Capture as many forms of genericity as possible
* The front language should be natural and intuitive

## Definition of Done
1. Fuse every monotyped Tensor operation
2. Incl. Product types
3. Incl. Sum types

## Lens' get,set and traverse are array functions
lenses: get, set and traverse are list operations, so what stops us from simply using our list infrastructure ? poor haskell has to rely on hacky simulations of subtyping and template-haskell in order to power lens.

The ideal solution requires tuples to subsume arrays (eg. `(Int,String) is a valid [a]`). This requires flexible typevariables, covariant subsumption in type constructors, and subtyping.

Lens.Prism: or how to handle sumtypes ? prisms return 'Maybe a', since the shape of a recursive sumtype is irregular, especially in the presence of recursive data, which represents seperate functionality to handle sumtypes (crucially for this sumtypes must be typed as polytypes: AltTy1 | AltTy2 .. , both for prisms and for subtyping in general)

## Array Oriented
Array Oriented programming involves generalizing operations over Tensors (shaped arrays):
```J
NB. in J
0 1 + 1 = 1 2
1 2 + 2 1 = 3 3
```
Some typed examples
```haskell
-- normal zip vs. join at rank 1 (sometimes called 'stitch')
zip : [a] -> [b] -> [(a,b)]
(,) : [a] -> [a] -> [[a,a]] -- note. (,) takes lists, so it's rank = 1 1

-- Array oriented zipWith
zipWith : (a->b->c) -> [a] -> [b] -> [c]
zipWith f a b = (fold f [] @ _1) (a , b)  -- (a,b) has type [a]
```
### Agreement
Array languages usually only offer functions of arity 1 or 2 (Monad/Dyad verbs in J terminology). Agreement for Dyads:
1. split the arrays into macro-cells according to the rank of the verb - the remaining shape is called the 'frame' of the argument. So for verbs of rank 0 0, the frames are simply the shape of each argument
2. the frames must match identically for the entire length of the shorter frame.
3. We must account for the surplus frame: by looping over it and executing the verb on all macrocells.

So functions could automatically find agreement on arbitrary tensors; obviously this behavior can be toggled by importing (or not) Tensor overloads for (+) etc.. Concretely, a 'match' function is needed to handle agreement.
```haskell
-- match implements this logic, for use in overloads on tensors, eg. (+) (-) etc..
-- match assumes step 1. has been done (it doesn't know the verb's rank); it handles agreement of surplus frames
type Shape = [Nat]
match1 : (x->y) -> Shape -> (Tensor a->Tensor b)
match2 : (x->y->z) -> Shape -> Shape -> (Tensor a->Tensor b->Tensor c)
matchN -- unclear complications, but notice a direct link to zipWithN (matchN @ _1)

-- modify rank
(@) : (x->y) -> n=Nat -> (a->b)
-- A more generic version should take a [Nat], one for each argument
```
matchN and (@) for arbitrary functions requires arity-genericity. It's worth noting that zipwithN is matchN at rank \_1

## Fold-Build
```haskell
buildGen f = f (,) [] -- where (,) is similar to haskell (:)
--eg.
map f xs = buildGen (\c n -> foldr (c << f) n xs)
sum = foldr (+) 0
down m = buildGen (\c n -> letrec loop x = if x<=0 then n else c x (loop (x-1)))
-- then
sum $ map (^2) (down z)
= foldr (+) 0 $ buildGen (\c n -> foldr (c << (^2)) n (down z))
= foldr ((+) << (^2)) 0 (down z)
= letrec loop x = if x<=0 then 0 else x^2 + loop (x-1) in loop z
-- which could even be reworked into a tail call by the optimizer (gcc is able to do so even with no purity guarantees)
```
Tensor Fusion: To achieve fusion at any rank, we need the folds to match the builds. If we always fold along the ravel, we lose useful information. The most sensible plan then, is to define several builds, with the idea to exploit the additional information. A couple of important notes:
* build is not an everyday programmer function, so we can bend it to suit our optimization purposes
* ideal builds are those we can fold in many different ways
* Before or after typechecking? Fusion shouldn't interfere with typechecking errors, so we can either have the compiler recognize folds, do it in the statically typed Core language (not fun) or have tc errors be language primitives
```haskell
-- buildGen: worst case, since elements have to be calculated sequentially,
-- we can only fuse it with foldr
buildGen g      = g (,) []
foldr k z (buildGen g) = g k z

-- indexed build is ideal, it supports any fold at any rank easily:
buildI : Nat -> (Int -> a) -> Tensor a
buildI n fI      = fI @0 [0..n]

-- An additional benefit is seen in indexing operations: `buildIShape f ! 1 4 5 0`
buildIShape [Nat] -> (Int -> a) -> Tensor a
buildIShape n atI = n `shape` (buildI [0..] atI)
```

## Arity and Tensors
There is a known pattern in the functions: repeat, map, zipWith, zipWith3, zipWithN, They are known to be doubly-generic. I have also noted that zipWithN is exactly matchN @ \_1, so matchN is a rare case of a triply-generic function

```haskell
type Arrow (t:Type) = Stack (->) t -- Arrows are stacks of at least one type, using the (->) type constructor
-- The compiler should recognize Arrow stacks rather than (->) when type judging.
```

## Effects
```haskell
-- normal type for main
type IO = In & Out -- IO is a polytype of effects
main : [String] -> Byte % IO
main = print (filter (\match '.' , _) readDir pwd)

```
Unlike Frank, We cannot afford to define an order of operations for function arguments: we would no longer be free to multithread nor rearrange arguments: (eg. if only one function wants to inplace a data, then we should call it last and let it do so). Additionally we don't want effects to be a compiler speciality; that would indicate a failure of the type system. The main question there is how we would produce clear error messages, however that is an issue in any case since we may often want to craft custom typecheck errors, esp. for purposes of ignoring irrelevant type refinements.

What is the type of an Effect ? Pretty much a product polytype (&), similar, but more flexible than a haskell constraint. Ultimately stateful effects need to become monads, after which 2 questions arise:
1. How to insert the effect combinators `<$> <*> >>=`
2. How to derive effect combinators: `(>>=)` is distributive over composition for many monads, but not all (eg. `Maybe`)
